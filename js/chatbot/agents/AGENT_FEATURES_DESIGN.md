# 智能代理 (Agent) 功能设计文档

## 1. 总体目标

在现有聊天机器人基础上，集成高级智能代理功能，以增强对超长文本的处理能力，实现类似检索增强生成 (RAG) 的效果，并与现有的TOC（目录）分段机制、高亮标注等富文本信息进行有效联动。

## 2. 文件结构

新的 Agent 相关代码将组织在 `js/chatbot/agents/` 目录下：

-   `js/chatbot/agents/long-text-agent.js`: 处理超长文本的分段、摘要、智能选段等。
-   `js/chatbot/agents/retrieval-agent.js`: 实现RAG相关的检索逻辑。
-   `js/chatbot/agents/base-agent.js`: (可选) 提供Agent的基类或通用工具。
-   **(新增考虑)** 可能会集成第三方库如 Orama (`@orama/orama`) 及其相关插件，用于在前端实现高效的全文及向量搜索。

## 3. Agent 核心功能

### 3.1. 超长文本处理 Agent (`LongTextAgent`)

#### 3.1.1. 智能分段
-   **输入**: 完整文档文本。
-   **逻辑**:
    -   借鉴 `toc_logic.js` 中精细的标题识别和层级构建逻辑，实现比 `ChatbotCore.splitContentSmart` 更语义化的分段。
    -   确保每个生成的文本段落能够与TOC结构中的条目（或其代表的文档区域）对应起来。
    -   考虑字符数超过5万字的情况，确保Agent能有效处理。
-   **输出**: 结构化的文本段落列表，每个段落包含内容、ID，并尽可能关联到TOC节点。

#### 3.1.2. 段落摘要与重点提取
-   **输入**: 单个文本段落。
-   **逻辑**:
    -   调用大语言模型 (可基于 `ChatbotCore.singleChunkSummary`) 对每个段落进行摘要或提取关键信息。
    -   对于与TOC块对应的段落，可以生成该TOC"块"级别的重点，或进行内容改写。
-   **输出**: 段落的摘要或关键点列表。

#### 3.1.3. 智能选段与上下文构建
-   **输入**: 用户查询、所有处理过的文本段落（含摘要）、聊天历史（可选）、TOC结构。
-   **逻辑**:
    -   根据用户查询，通过LLM判断或传统文本相似度计算（如TF-IDF、向量相似度），选出最相关的N个文本段落。
    -   将被选中的段落内容（或其摘要）、相关的TOC信息、以及文档中的其他富信息（如用户高亮、图片OCR文本、表格数据、标注信息）整合起来。
    -   构建一个精简但信息丰富的上下文，供主聊天模型使用。
-   **输出**: 优化后的上下文信息。

#### 3.1.4. 上下文管理
-   **逻辑**:
    -   设计一种"折叠式"的上下文系统，平时只加载关键信息或摘要。
    -   当用户交互深入到特定主题或段落时，"展开"更详细的内容。
    -   Agent的交互过程和状态（如AI选择的相关段落、用户确认的段落）可以使用JSON等结构化数据进行记录和传递，方便后续复用和调试。

#### 3.1.5. 预处理与"精简内容树" (新增)
-   **触发**: 首次加载超长文档时。
-   **逻辑**:
    -   可向用户提议，对文档进行一次性预处理，生成"精简内容树"。此树包含文档的结构化摘要、关键概念、以及与TOC的映射关系。
    -   生成过程可利用并发处理（例如，各章节/段落并行摘要）和成本效益较高的模型来优化效率。
-   **输出**: 缓存的"精简内容树"，供后续用户查询时快速调用，显著减少实时处理时间。
-   **后续使用**: 在用户后续提问时，`LongTextAgent` 可以优先基于此"精简内容树"进行智能选段和上下文构建，同样可以并发处理树中各节点的相关性分析。

### 3.2. 检索增强 Agent (`RetrievalAgent`) (基于 Orama 的前端 RAG)

本 Agent 旨在通过在客户端实现的语义和关键词搜索能力，为聊天机器人提供检索增强生成 (RAG) 的核心功能。我们将利用 Orama (`@orama/orama`) 这个强大的纯 JavaScript 搜索引擎库，它支持全文搜索、向量搜索以及混合搜索，并且能够将索引持久化存储在浏览器端。

-   **核心技术**: Orama 搜索引擎库。

-   **索引构建 (Indexing)**:
    -   **触发时机**:
        -   当 `LongTextAgent` 完成对文档的智能分段后。
        -   当用户首次加载文档，并同意进行预处理以构建"精简内容树"和搜索索引时。
        -   当应用加载时，尝试从客户端存储（如 IndexedDB 或 localStorage）恢复已持久化的 Orama 索引。
    -   **数据来源**: 由 `LongTextAgent` 生成的文本段落/块，或"精简内容树"中的节点内容。
    -   **嵌入向量生成**:
        -   **方案1 (推荐)**: 利用 Orama 的插件，如 `@orama/plugin-embeddings` 配合 TensorFlow.js 在设备端直接生成嵌入，或使用 `@orama/plugin-secure-proxy` 安全地调用外部嵌入API（如 OpenAI）来生成文本块的向量嵌入。这些插件可以简化嵌入的生成和管理。
        -   **方案2 (手动)**: 应用自行调用选择的嵌入模型API，获取每个文本块的向量嵌入。
    -   **Orama Schema 定义**: 定义包含文本内容字段（用于全文搜索）和向量字段（例如 `embedding: "vector[1536]"`，维度需与所用嵌入模型匹配）的 schema。
    -   **数据注入**: 将文本块及其对应的向量嵌入（如果适用）注入到 Orama 实例中进行索引。
    -   **持久化**: 利用 Orama 的 `@orama/plugin-data-persistence` 插件，将构建好的索引序列化并存储到客户端（如 IndexedDB），以便后续快速加载，避免重复处理。

-   **检索逻辑 (Retrieval Logic)**:
    -   **触发条件**: 当主聊天模型或 `LongTextAgent` 判断当前上下文不足以回答用户问题时，或者用户明确激活了深度检索功能。
    -   **用户查询处理**: 获取用户查询的文本。
        -   如果使用 Orama 插件自动处理嵌入，可以直接将文本查询传递给 Orama。
        -   否则，需先将用户查询文本发送到嵌入模型 API 获取其向量嵌入。
    -   **执行搜索**:
        -   **向量搜索**: 使用 Orama 的 `search` 功能，设置 `mode: "vector"`，提供查询向量（或让插件处理查询文本），在预定义的向量字段上进行搜索，获取基于语义相似度的文本块。
        -   **混合搜索 (Hybrid Search)**: 利用 Orama 的 `mode: "hybrid"` 功能，结合向量搜索的语义相关性和传统全文搜索（如 BM25，Orama 内置支持）的关键词匹配能力，以获得更全面的结果。
        -   **参数配置**: 可配置相似度阈值、返回结果数量等。
    -   **结果处理**: Orama 返回按相关性排序的文档块列表（包含原始文本、ID、得分等）。

-   **上下文构建与输出**:
    -   将被 Orama 检索到的最相关的 N 个文本段落/节点（及其内容或摘要）、相关的TOC信息、文档中的其他富信息（用户高亮、OCR文本等）整合起来。
    -   构建一个精简但信息丰富的上下文，供主聊天模型使用，或直接向用户展示检索结果。
    -   此步骤与 `LongTextAgent` 的 `3.1.3. 智能选段与上下文构建` 中关于整合BM25结果的思路一致，Orama 的混合搜索能力可以直接支持这一点。

-   **优势**:
    -   在纯前端环境实现强大的语义搜索和关键词搜索。
    -   利用 Orama 的优化和持久化能力，提升性能和用户体验。
    -   简化了之前手动管理嵌入向量存储和相似度计算的复杂性。

## 4. 调用流程与集成

-   **触发点**:
    -   在 `ChatbotCore.sendChatbotMessage` 函数内部，发送给LLM之前。
    -   或者在 `chatbot-ui.js` 的 `handleChatbotSend` 中，根据输入文本长度或用户在浮动选项中激活的Agent功能，决定是否先调用Agent。
-   **数据流**:
    1.  用户输入。
    2.  UI层判断是否需要Agent介入。
    3.  若需要，调用相应的Agent (如 `LongTextAgent`)。
    4.  Agent进行分段、摘要、选段等操作，构建精炼上下文。
    5.  (可选) 如果上下文仍不足，`LongTextAgent` 或主控逻辑可调用 `RetrievalAgent` 进一步增强上下文。
    6.  最终的精炼上下文传递给 `ChatbotCore.sendChatbotMessage` 中的LLM调用部分。
    7.  LLM的回复正常返回并由UI渲染。

## 5. UI/UX 考虑

-   **浮动选项 (`chatbot-floating-options.js`)**:
    -   可能需要增加新的开关来启用/禁用特定的Agent功能（例如"智能长文处理模式"、"深度检索模式"）。
-   **消息渲染 (`chatbot-message-renderer.js`)**:
    -   考虑如何向用户展示Agent的工作过程或中间结果，例如：
        -   提示用户当前正在对长文进行智能处理。
        -   高亮显示AI认为与问题最相关的文档片段。
        -   允许用户查看或选择Agent提取出的关键段落。
-   **用户交互**:
    -   允许用户对Agent选择的段落进行反馈或调整。
    -   **(新增)** 主动预处理提示: 对于超长文档，首次加载时可友好提示用户是否愿意花费一些时间预先生成"精简内容树"，以便后续实现更快速、更智能的交互。

## 6. 待定与未来展望
-   Agent之间协作的复杂逻辑。
-   用户自定义Agent行为的接口。
-   更细致的上下文记忆和管理策略。

只要Agent模式能够显著提升信息获取的质量、深度以及与用户研究意图的契合度（例如，通过智能选段提供更精准的上下文，辅助理解复杂文献），这种成本和延迟的增加是可以接受的。**(新增)** 同时，通过采用并发处理、优化模型选择（例如，对部分预处理步骤使用更经济的模型）以及预生成"精简内容树"等策略，可以有效控制和优化实际的处理时长与开销。

## 7. 科研场景下的特定考量与设计权衡

在将 Agent 模式应用于科研辅助的特定场景时，我们对传统模式的优缺点进行了深入分析，并结合用户（科研人员）的实际需求，对以下几点进行了权衡：

### 7.1. 成本与延迟的接受度

科研工作往往追求深度、准确性和全面的信息获取。因此，相较于对低成本和极致低延迟的追求，科研用户通常更愿意接受因Agent模式带来的：

-   **更高的计算成本**：由于可能涉及多次LLM调用（例如，用于分段优化、段落摘要、相关性判断、最终答案生成等）。
-   **一定的处理延迟**：多阶段、更复杂的处理流程自然会比单一的传统检索耗时更长。

只要Agent模式能够显著提升信息获取的质量、深度以及与用户研究意图的契合度（例如，通过智能选段提供更精准的上下文，辅助理解复杂文献），这种成本和延迟的增加是可以接受的。**(新增)** 同时，通过采用并发处理、优化模型选择（例如，对部分预处理步骤使用更经济的模型）以及预生成"精简内容树"等策略，可以有效控制和优化实际的处理时长与开销。

### 7.2. 错误累积风险与缓解策略

Agent模式的链式处理特性（例如：分段 -> 摘要 -> 选段 -> 生成）确实带来了错误累积的风险，即前一阶段的错误或偏差可能会被放大并传递到后续阶段，影响最终结果的准确性。针对这一风险，考虑以下缓解策略：

-   **提升模块健壮性**：持续优化每个独立Agent（如 `LongTextAgent`, `RetrievalAgent`）内部逻辑的准确性和鲁棒性。
-   **引入用户交互与反馈**：
    -   如"5. UI/UX 考虑"中提及，允许用户查看Agent选择的关键段落，并进行调整或确认。这能有效中断错误传递链条。
    -   设计明确的提示，告知用户当前是Agent在进行处理，以及处理到了哪个阶段。
-   **过程透明化与可追溯性**：
    -   尽可能让Agent的中间决策（如哪些段落被认为相关）对用户可见。
    -   记录Agent处理的关键步骤和中间数据，便于调试和问题定位。
-   **设计回退与容错机制**：当某个Agent的处理结果置信度较低或出现明显错误时，可以考虑提供备选的、更简单或更保守的处理路径。

### 7.3. "黑盒"决策与AI语义理解的价值

Agent模式中的关键环节（如智能选段、摘要生成）依赖大型语言模型的语义理解能力，其内部决策过程在一定程度上是"黑盒"。对此，我们的考量是：

-   **价值优先于完全可解释性**：在科研场景，如果AI通过其语义理解能力选出的上下文、生成的摘要能够显著帮助用户理解文献、启发思路或提高研究效率，那么即使其决策过程不完全透明，其应用价值依然巨大。
-   **输出结果的可验证性**：虽然LLM的"思考"过程是黑盒，但其输出（如选择的文本片段、生成的摘要）是用户可以直接审查和验证的。用户可以基于自己的专业知识判断AI提供的信息是否准确、相关。
-   **信任与迭代**：通过持续观察和评估Agent在实际科研任务中的表现，逐步建立对AI能力的信任，并通过用户反馈和模型迭代不断优化其准确性和可靠性。

通过上述考量和设计，我们旨在使Agent模式不仅功能强大，而且在科研辅助这一特定应用中更加实用和可靠。
